name: Update dataset

on:
  # Executa todo domingo às 06 h UTC e quando você clicar “Run workflow”
  schedule:
    - cron: "0 6 * * 0"
  workflow_dispatch:

jobs:
  refresh:
    runs-on: ubuntu-latest

    steps:
      # Clona seu repo
      - uses: actions/checkout@v4

      # Python 3.11
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # Instala kaggle-cli
      - run: pip install kaggle --quiet

      # ↓↓↓ PASSO CRÍTICO — baixa o ZIP, descompacta e deleta o zip ↓↓↓
      - name: Download latest ZIP from Kaggle
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY:      ${{ secrets.KAGGLE_KEY }}
        run: |
          mkdir -p data
          kaggle datasets download -d datahackers/state-of-data-brazil-20242025 -p data --force
          unzip -o data/state-of-data-brazil-20242025.zip -d data
          rm      data/state-of-data-brazil-20242025.zip

      # Commita só se o CSV mudou
      - name: Commit & push if dataset changed
        run: |
          git config --global user.name  "github-actions"
          git config --global user.email "actions@users.noreply.github.com"
          git add data/df_survey_2024.csv || true
          if ! git diff --cached --quiet; then
            git commit -m "chore(data): refresh SoD CSV" && git push
          else
            echo "No dataset update"
          fi
